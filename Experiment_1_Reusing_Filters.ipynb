{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment 1 - Reusing Filters.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdOlc6v0JukugLnzYc+hKW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99UPO3nfm8t9",
        "colab_type": "text"
      },
      "source": [
        "###Experiment 1 - Reusing Learned Filters - This is most likely a trivial experiment, but it may be interesting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tk3eOXZx-TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "import jax\n",
        "import numpy as onp\n",
        "import matplotlib.pyplot as py\n",
        "import tensorflow as tf #this is only for dataset loading. \n",
        "tf.config.experimental.set_visible_devices([], \"GPU\") #To prevent OOM GPU error when tf allocates memory preemptively. \n",
        "from jax import grad,jit,vmap\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import timeit\n",
        "from jax import device_put"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlP27Ak_D084",
        "colab_type": "text"
      },
      "source": [
        "####MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LoHzkE5LWrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89bcde97-9a7c-45c6-f981-f4e568dae955"
      },
      "source": [
        "(train_mnist_data,train_mnist_labels),(test_mnist_data,test_mnist_labels)=tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq75zHapdFWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mnist_data=device_put(train_mnist_data, jax.devices('gpu')[0])\n",
        "train_mnist_labels=device_put(train_mnist_labels, jax.devices('gpu')[0])\n",
        "test_mnist_data=device_put(test_mnist_data, jax.devices('gpu')[0])\n",
        "test_mnist_labels=device_put(test_mnist_labels, jax.devices('gpu')[0])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ye3MPnD2vc",
        "colab_type": "text"
      },
      "source": [
        "####Fashion-MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heib_jnUD6Rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a29e4562-17d7-4900-d58b-b0e8d92dafeb"
      },
      "source": [
        "(train_fash_data,train_fash_labels),(test_fash_data,test_fash_labels)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lv9jfSD7_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_fash_data=device_put(train_fash_data, jax.devices('gpu')[0])\n",
        "train_fash_labels=device_put(train_fash_labels, jax.devices('gpu')[0])\n",
        "test_fash_data=device_put(test_fash_data, jax.devices('gpu')[0])\n",
        "test_fash_labels=device_put(test_fash_labels, jax.devices('gpu')[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rmXCNFkdUp_",
        "colab_type": "text"
      },
      "source": [
        "### Main Convolution Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaWDuf10eOWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Maxpooling operation, takes a numpy matrix of shape (depth,width,height), applies a max on a kernel of shape (nrows,ncols) for each feature map \n",
        "def max_pool(image, nrows, ncols): \n",
        "    #Splits into submatrix and output max value\n",
        "    output=[]\n",
        "    d,ow,oh = image.shape\n",
        "    for i in range(image.shape[0]): #this is repeated for each filter. \n",
        "      array=image[i].reshape(ow,oh)\n",
        "      r, h = array.shape\n",
        "     \n",
        "      temp=(array.reshape(h//nrows, nrows, -1, ncols)\n",
        "                  .swapaxes(1, 2)\n",
        "                  .reshape(-1, nrows, ncols))\n",
        "        \n",
        "      output.append(np.max(temp.reshape(-1,4),axis=1))\n",
        "    output=np.array(output)\n",
        "     \n",
        "    output=output.reshape(image.shape[0],int(ow/nrows),int(oh/ncols))\n",
        "    return output\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJacm1rBSxwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is technically incorrectly labelled as an adjacency matrix function. Thought I had an implementation using an adjacency matrix.\n",
        "\n",
        "#The function generates a vector of shape (padded_image_height * padding_image_width, un_padded_image_height*un_padded_image_width) \n",
        "#Using this function, the indices for each convolution can be determined for the incomming image to allow that data to be quickly mapped into columns as you will see in\n",
        "#the 'im2col' function. By default the function is limited to 3x3 kernel, however the kernel size can technically be changed.\n",
        "\n",
        "#Note, this function assumes 'same' padding ONLY.\n",
        "def adj_matrix(row,height,padding):  \n",
        "  padding=padding*2\n",
        "  row=row+padding\n",
        "  height=height+padding\n",
        "  am =onp.zeros(((row)*(height),(row-padding)*(height-padding))) #adj matrix with 11*11 inputs, with 1 kernel doing an entire convolution for now. Imagine the first diemsnion like a linear line (For now only works on equal sized images. \n",
        "  \n",
        "  #one row has (max length-kernel_size) (so 30-3 or 27 strides per row, with 27 stides in columbs \n",
        "\n",
        "\n",
        "  start=0\n",
        "  end=3\n",
        "  jump = row #The jump is a row length\n",
        "  mod=0\n",
        "  ctr=0\n",
        "  for i in range(row-padding): #assigning the pixels to a given stride, which is maxed out at 28*28 due to assumed 'same' padding. \n",
        "    for j in range(height-padding):\n",
        "      am[start+mod:end+mod,ctr]=1\n",
        "      am[start+mod+jump:end+mod+jump,ctr]=1\n",
        "      am[start+mod+jump+jump:end+mod+jump+jump,ctr]=1\n",
        "      mod+=1\n",
        "      ctr+=1 \n",
        "    start=end-1\n",
        "    end =start+3\n",
        "\n",
        "  return am \n",
        "\n",
        "#im2col uses a matrix to generate the transform the image into all convolutions, and transforms all the convolutions into columns to allow \n",
        "#fast compute due to the use of matrix multiplication without loops. \n",
        "#This function does this by taking the tranpose of the matrix and performs multiplication with padded placeholder matrix, to generate a \n",
        "#vector containing all the indices of a given shaped input into a large matrix. \n",
        "\n",
        "def im2col(row,height,depth,padding):\n",
        "  padded_image=onp.ones(((row+(padding*2))*(row+(padding*2)))).astype('float16')\n",
        "  am=adj_matrix(row,height,padding)\n",
        "  indices=am.T*padded_image #this can theoretically be used to make any shaped kernels, by modifying the way the matrix is created. \n",
        "  window_indices=[]\n",
        "  image_indices=[]\n",
        "  for i in range(row*height):\n",
        "    window_indices.append(onp.nonzero(indices[i])[0])\n",
        "  window_indices=np.array(window_indices).T\n",
        "  image_indices.append(window_indices)\n",
        "  for i in range(1,depth): #This adds the additional indices for each layer of the image.\n",
        "    window_indices=window_indices+((row+(padding*2))*(row+(padding*2)))\n",
        "    image_indices.append(window_indices)\n",
        "  return onp.array(image_indices)\n",
        "\n",
        "#This function adds padding aroud any image such that after convolution is performed the resultant image will have the same dimensions\n",
        "#as the input. This function is also known as 'same' padding in tensorflow.\n",
        "\n",
        "def add_pad (image_,kernelw_,kernelh_):  #input image are channel,h,w\n",
        "  #new add_pad\n",
        "  d,h,w=image_.shape\n",
        "  #d=1\n",
        "  padw=onp.zeros((d,w,onp.divmod(kernelw_,2)[0]))\n",
        "\n",
        "  padded=np.concatenate([padw,image_],axis=2) #you want to add, at the start if a \n",
        "  padded=np.concatenate([padded,padw[:]],axis=2)\n",
        "\n",
        "  padh=onp.zeros((d,onp.divmod(kernelh_,2)[0],padded.shape[2]))\n",
        "\n",
        "  padded=np.concatenate([padh,padded],axis=1)\n",
        "  padded=np.concatenate([padded,padh],axis=1)\n",
        "  return padded\n",
        "\n",
        "#This is the convolution function, which does not use any loop, making it a relatively fast computation. The convolution takes a kernel  of 3x3xdepth shape (or shaped\n",
        "#defined by the im2col matrix, performs a dot product with the equvilant shaped weight matrix for a given number of filters as defined by the parameters. \n",
        "\n",
        "def conv (input_image,parameter,im2col_matrix): #parameter will be shaped. [layer,weight/bias,filter#], on input the parameter will be just [weight/bias,filter#]\n",
        "  d,h,w = input_image.shape\n",
        "  kh,kw=parameter[0][0][0].shape #fetches the kernel size\n",
        "  \n",
        "  weights=parameter[0].reshape(-1,d*kh*kw) #changes the kernel into [filter,3*3] to linearlize. \n",
        "\n",
        "  input_image=add_pad(input_image,kh,kw) #add padding \n",
        "  input_image = input_image.flatten() \n",
        "  conv_image=input_image[im2col_matrix].T \n",
        "  conv_image=conv_image.reshape(w*h,kh*kh*d) #Flattens all the kernels into a row, allowing a dot product to be performed on all the filters at once. \n",
        "  convolved=(np.dot(conv_image,weights.T) + parameter[1]).T\n",
        "  convolved=convolved.reshape(len(parameter[0]),h,w)\n",
        "\n",
        "  return convolved\n",
        "\n",
        "jit_conv_layer=conv #Jax is used to just_in_time compile to further speed up the convolution. \n",
        "  \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Jy97WmoWRt",
        "colab_type": "text"
      },
      "source": [
        "###Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATkC-GHQdYEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#so the weights will be the shape.\n",
        "#number of filters,image_depth,kernelW,kernelH.\n",
        "\n",
        "def init_conv_parameters(filters,size,image_depth):  \n",
        "  trainable_v=[]\n",
        "  size_f=size[0]*size[1] \n",
        "  trainable_v.append([]) #new layer\n",
        "  trainable_v[0].append(onp.random.rand(filters[0],image_depth, size[0],size[1])) #this assumes first channel is 1 so this will not work with RBG channels for now. \n",
        "  trainable_v[0].append(onp.random.randn(filters[0]))#bias\n",
        "  #trainable_v[0].append(onp.zeros(filters[0]))#bias\n",
        "  for i in range(1,len(filters)):  #for a given layer \n",
        "    trainable_v.append([])\n",
        "    trainable_v[i].append(onp.random.rand(filters[i],filters[i-1],size[0],size[1])) #The kernel will be previous layer size. for now assume it's square. \n",
        "    trainable_v[i].append(onp.random.randn(filters[i]))\n",
        "    #trainable_v[i].append(onp.zeros(filters[i]))\n",
        "  return trainable_v\n",
        "\n",
        "\n",
        "def init_parameters(shapes,input_shape=784):  \n",
        "    onp.random.seed(1000)\n",
        "    trainable_v=[[]]\n",
        "    #first layer\n",
        "    trainable_v[0].append(onp.random.randn(shapes[0],input_shape)) #input\n",
        "    trainable_v[0].append( onp.random.randn (shapes[0])) #bbias \n",
        "    for i in range(1,len(shapes)): \n",
        "      trainable_v.append([]) #creates new layer?\n",
        "      trainable_v[i].append(onp.random.randn(shapes[i],shapes[i-1]))\n",
        "      trainable_v[i].append(onp.random.randn(shapes[i]))\n",
        "    return trainable_v\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqxcKrE7N8fP",
        "colab_type": "text"
      },
      "source": [
        "### Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaPjwxmo8usi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tanh_act(x): \n",
        "    return np.tanh(x)\n",
        "def sigmoid_act(x): \n",
        "  return jax.nn.sigmoid(x)\n",
        "def softmax_act(x): \n",
        "    #return np.exp(x)/(np.sum(np.exp(x)))\n",
        "    return jax.nn.softmax(x)\n",
        "def binary_crossentropy(x,y): #x=input, y= target\n",
        "    return -y*np.log(x)-(1-y)*np.log(1-x)\n",
        "    #return jax.nn.binary_crossentropy(x,y)\n",
        "def relu_act(x): \n",
        "  return jax.nn.relu(x)\n",
        "def normalize(x): \n",
        "  return jax.nn.normalize(x,axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU68HW_gsgGW",
        "colab_type": "text"
      },
      "source": [
        "#Initial Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gewamnrDsfln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(params,i2c_matrix,input):\n",
        "  #2 Convolution Layers.\n",
        "  layer1=jit_conv_layer(input,params[0],i2c_matrix[0])\n",
        "  layer1=relu_act(layer1)\n",
        "  sampler=layer1\n",
        "  layer1=max_pool(layer1,2,2) #28--14\n",
        " \n",
        "\n",
        "  layer2=jit_conv_layer(layer1,params[1],i2c_matrix[1])\n",
        "  layer2=relu_act(layer2)\n",
        "  layer2=max_pool(layer2,2,2) #14-7\n",
        "\n",
        "\n",
        "  ###FC network starts\n",
        "  layer2=layer2.flatten()\n",
        "  l1=np.dot(layer2,params[2][0].T)+params[2][1]\n",
        "  l1=jax.nn.normalize(l1)\n",
        "  l1=relu_act(l1)\n",
        "  \n",
        "  l2=np.dot(l1,params[3][0].T)+params[3][1] \n",
        "  l2=jax.nn.normalize(l2)\n",
        "\n",
        "  \n",
        "  l2=softmax_act(l2)\n",
        "  return [l2,sampler]\n",
        "\n",
        "vmap_forward=vmap(forward,in_axes=(None,None,0)) #jax.vmap is used to vectorize the process to allow for batching. \n",
        "\n",
        "\n",
        "def NLL(x,y): \n",
        "    return -np.log(x[np.argmax(y)]) #assuming one hot\n",
        "\n",
        "\n",
        "def NLL_loss(params,i2col_matrix,i,t): \n",
        "  pred,_=jit(forward)(params,i2col_matrix,i)\n",
        "  final=jit(NLL)(pred,t)\n",
        "  return final\n",
        "\n",
        "\n",
        "#Function to update parameters after gradient is calculated. \n",
        "#assumes the gradient input has shape [batch_size,weight matrix]\n",
        "#Mini-batch SGD --> summed gradients. \n",
        "def update_weights(params, gradient ,lr=1.0): \n",
        "  for i in range(len(params)): #iterate through the layer. \n",
        "    params[i][0]=params[i][0]-(lr*np.sum(gradient[i][0],axis=0))\n",
        "    params[i][1]=params[i][1]-(lr*np.sum(gradient[i][1],axis=0))\n",
        "  return params\n",
        "\n",
        "\n",
        "gradient=jit(grad(NLL_loss,argnums=(0)))\n",
        "vmap_backprop = vmap(gradient,in_axes=(None,None,0,0))\n",
        "jit_grad =jit(vmap_backprop)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgccDp5cQUUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e05fb438-01b9-495d-b68c-616414beef1c"
      },
      "source": [
        "test_mnist_data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMwRfPqKKfdo",
        "colab_type": "text"
      },
      "source": [
        "####First Network - MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D71CO02XYuJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preparing and normalizing data. \n",
        "\n",
        "train_mnist_data=train_mnist_data.reshape(60000,1,28,28)/255.0\n",
        "train_mnist_label=to_categorical(train_mnist_labels)\n",
        "\n",
        "\n",
        "test_mnist_data=test_mnist_data.reshape(10000,1,28,28)/255.0\n",
        "test_mnist_label=to_categorical(test_mnist_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK65IL7MZiMz",
        "colab_type": "text"
      },
      "source": [
        "###Network1 initialization of weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KG4Dd_pfzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initializing weights.\n",
        "\n",
        "onp.random.seed(1100)\n",
        "conv_params =init_conv_parameters(filters=[32,16],size=[3,3],image_depth=1)\n",
        "fc_params=init_parameters([300,10],input_shape=784)\n",
        "params1=conv_params+fc_params #totalling 2 convs layers, 2 fc layers \n",
        "im2col_matrix_network1=[]\n",
        "im2col_matrix_network1.append(im2col(row=28,height=28,depth=1,padding=1)) #This is the initial size so mnist starts at 1, but with 4 filters the next layer will be 4. \n",
        "im2col_matrix_network1.append(im2col(row=14,height=14,depth=32,padding=1))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrWFYZR_Odix",
        "colab_type": "text"
      },
      "source": [
        "###Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG28uUvbrZfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d74e0dd9-d11e-4a17-c3bb-64256c4d14b6"
      },
      "source": [
        "dense_jit=jit(vmap_forward) #speed up\n",
        "#jit_backprop=jit(vmap_backprop)\n",
        "jit_update_weights=jit(update_weights)\n",
        "\n",
        "ctr=0\n",
        "\n",
        "for i in range(5): #epochs\n",
        "  start_time = timeit.default_timer()\n",
        "  for j in range(400): #number of batches to iterate.\n",
        "    \n",
        "    dparams=jit_grad(params1,im2col_matrix_network1,train_mnist_data[ctr:ctr+100],train_mnist_label[ctr:ctr+100]) #The last value is batch size\n",
        "    params1= jit_update_weights(params1,dparams,lr=1.00)\n",
        "    ctr=ctr+100\n",
        "\n",
        "    if ctr+100>40000:\n",
        "      ctr=0\n",
        "  elapsed = timeit.default_timer() - start_time\n",
        "  print (f'epoch time: ' ,elapsed)  \n",
        "  pred,_=dense_jit(params1,im2col_matrix_network1,train_mnist_data[40300:40400])\n",
        "  pred=np.argmax(pred,axis=1)\n",
        "\n",
        "  targets=np.argmax(train_mnist_label[40300:40400],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(len(np.where(pred == targets)[0])/100*100)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch time:  2.628969063999989\n",
            "epoch:  1\n",
            "97.0\n",
            "epoch time:  2.61614455900002\n",
            "epoch:  2\n",
            "97.0\n",
            "epoch time:  2.6148333579999985\n",
            "epoch:  3\n",
            "97.0\n",
            "epoch time:  2.6210735919999593\n",
            "epoch:  4\n",
            "98.0\n",
            "epoch time:  2.6251910839999937\n",
            "epoch:  5\n",
            "98.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAO-433yP9zn",
        "colab_type": "text"
      },
      "source": [
        "### Model Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bPwIXkCP3Br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab373164-88d3-4a55-aa2f-e2a7035da1e3"
      },
      "source": [
        "#full test accuracy\n",
        "pred_1,_=dense_jit(params1,im2col_matrix_network1,test_mnist_data)\n",
        "pred_1=np.argmax(pred_1,axis=1)\n",
        "target_1=np.argmax(test_mnist_label,axis=1)\n",
        "print(len(np.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SlG91OJEzZy",
        "colab_type": "text"
      },
      "source": [
        "#First two layers are Conv filters, remaining 2 layers are FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZi07obplCGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_temp = params1[0:2] #borrow parameters from layer 1 and 2 both are convolutions."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zlbDFh8l_Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onp.random.seed(1100)\n",
        "params2=init_parameters([300,10],input_shape=784) #new fc-parameters, the conv-temp will be held frozen."
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGOYcJFm-H9",
        "colab_type": "text"
      },
      "source": [
        "#Modified Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03aXSXGCmAxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_mod(params,conv_parameters,i2c_matrix,input):\n",
        "  #2 Convolution Layers.\n",
        "  layer1=jit_conv_layer(input,conv_parameters[0],i2c_matrix[0])\n",
        "  layer1=relu_act(layer1)\n",
        "  sampler=layer1\n",
        "  layer1=max_pool(layer1,2,2) #28--14\n",
        " \n",
        "\n",
        "  layer2=jit_conv_layer(layer1,conv_parameters[1],i2c_matrix[1])\n",
        "  layer2=relu_act(layer2)\n",
        "  layer2=max_pool(layer2,2,2) #14-7\n",
        "\n",
        "\n",
        "  ###FC network starts\n",
        "  layer2=layer2.flatten()\n",
        "  l1=np.dot(layer2,params[0][0].T)+params[0][1]\n",
        "  l1=jax.nn.normalize(l1)\n",
        "  l1=relu_act(l1)\n",
        "  \n",
        "  l2=np.dot(l1,params[1][0].T)+params[1][1] \n",
        "  l2=jax.nn.normalize(l2)\n",
        "\n",
        "  \n",
        "  l2=softmax_act(l2)\n",
        "  return [l2,sampler]\n",
        "\n",
        "vmap_forward=vmap(forward_mod,in_axes=(None,None,None,0)) #jax.vmap is used to vectorize the process to allow for batching. \n",
        "\n",
        "\n",
        "def NLL(x,y): \n",
        "    return -np.log(x[np.argmax(y)]) #assuming one hot\n",
        "\n",
        "\n",
        "def NLL_loss(params,conv_parameters,i2col_matrix,i,t): \n",
        "  pred,_=jit(forward_mod)(params,conv_parameters,i2col_matrix,i)\n",
        "  final=jit(NLL)(pred,t)\n",
        "  return final\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZXGBleKmmYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradient=jit(grad(NLL_loss,argnums=(0)))\n",
        "vmap_backprop = vmap(gradient,in_axes=(None,None,None,0,0))\n",
        "jit_grad =jit(vmap_backprop)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B2a6uoQoJsp",
        "colab_type": "text"
      },
      "source": [
        "##Preprocess new data for network2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0lEPVToMsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preparing and normalizing data. \n",
        "\n",
        "train_fash_data=train_fash_data.reshape(60000,1,28,28)/255.0\n",
        "#train_data=train_data.transpose((0,3,1,2))/255.0\n",
        "train_fash_label=to_categorical(train_fash_labels)\n",
        "\n",
        "#test_data=test_data.transpose((0,3,1,2))/255.0\n",
        "test_fash_data=test_fash_data.reshape(10000,1,28,28)/255.0\n",
        "test_fash_label=to_categorical(test_fash_labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzHvi1z0q_yz",
        "colab_type": "text"
      },
      "source": [
        "Training Loop Network 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hrwYxHXoSB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27ef3532-508d-4b64-a8c6-5f6cb694f6eb"
      },
      "source": [
        "dense_jit=jit(vmap_forward) #speed up\n",
        "#jit_backprop=jit(vmap_backprop)\n",
        "jit_update_weights=jit(update_weights)\n",
        "\n",
        "ctr=0\n",
        "\n",
        "for i in range(20): #epochs\n",
        "  start_time = timeit.default_timer()\n",
        "  for j in range(40): #number of batches to iterate. #10000 out of 60000\n",
        "    \n",
        "    dparams=jit_grad(params2,conv_temp,im2col_matrix_network1,train_fash_data[ctr:ctr+100],train_fash_label[ctr:ctr+100]) #The last value is batch size\n",
        "    params2= jit_update_weights(params2,dparams,lr=1.00)\n",
        "    ctr=ctr+100\n",
        "\n",
        "    if ctr+100>40000:\n",
        "      ctr=0\n",
        "  elapsed = timeit.default_timer() - start_time\n",
        "  print (f'epoch time: ' ,elapsed)  \n",
        "  pred,_=dense_jit(params2,conv_temp,im2col_matrix_network1,train_fash_data[40300:40400])\n",
        "  pred=np.argmax(pred,axis=1)\n",
        "\n",
        "  targets=np.argmax(train_fash_label[40300:40400],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(len(np.where(pred == targets)[0])/100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch time:  0.13306870799999615\n",
            "epoch:  1\n",
            "0.72\n",
            "epoch time:  0.12660153500002025\n",
            "epoch:  2\n",
            "0.77\n",
            "epoch time:  0.12555329600002096\n",
            "epoch:  3\n",
            "0.8\n",
            "epoch time:  0.12412431000001334\n",
            "epoch:  4\n",
            "0.8\n",
            "epoch time:  0.12608516000000236\n",
            "epoch:  5\n",
            "0.81\n",
            "epoch time:  0.12729413199997452\n",
            "epoch:  6\n",
            "0.82\n",
            "epoch time:  0.1295746210000175\n",
            "epoch:  7\n",
            "0.78\n",
            "epoch time:  0.12508163100000047\n",
            "epoch:  8\n",
            "0.81\n",
            "epoch time:  0.12348525599998084\n",
            "epoch:  9\n",
            "0.81\n",
            "epoch time:  0.12797957100002577\n",
            "epoch:  10\n",
            "0.84\n",
            "epoch time:  0.1215684739999574\n",
            "epoch:  11\n",
            "0.87\n",
            "epoch time:  0.1289692900000432\n",
            "epoch:  12\n",
            "0.83\n",
            "epoch time:  0.11947759999998198\n",
            "epoch:  13\n",
            "0.84\n",
            "epoch time:  0.12075738100003264\n",
            "epoch:  14\n",
            "0.83\n",
            "epoch time:  0.12303198899996914\n",
            "epoch:  15\n",
            "0.84\n",
            "epoch time:  0.12232298800000763\n",
            "epoch:  16\n",
            "0.84\n",
            "epoch time:  0.12403075700001409\n",
            "epoch:  17\n",
            "0.83\n",
            "epoch time:  0.12740847599997096\n",
            "epoch:  18\n",
            "0.85\n",
            "epoch time:  0.1328880100000447\n",
            "epoch:  19\n",
            "0.84\n",
            "epoch time:  0.1251675359999922\n",
            "epoch:  20\n",
            "0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89hPkaTl-xRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff6e52b8-60bc-49b7-eb5d-a1e292ce520b"
      },
      "source": [
        "#full test on fashion data\n",
        "pred_1,_=dense_jit(params2,conv_temp,im2col_matrix_network1,test_fash_data)\n",
        "pred_1=np.argmax(pred_1,axis=1)\n",
        "target_1=np.argmax(test_fash_label,axis=1)\n",
        "print(len(np.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dePoCVW_bum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}